use std::str;

use crate::{checkflags, lang::{is_sep, Language, Syntax}};

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub struct Token<'t> {
    kind: TokenKind,
    lexeme: &'t [char], // Lexeme; have it be empty if it is not being used (eg. for comments)
    start: usize,   // Start index          : print("Hello world") : iterate with start..end
    end: usize      // Index after last char: ^s   ^e              :              ^^^^^^^^^^
}

impl<'t> Token<'t> {
    pub fn new(kind: TokenKind, lexeme: &'t [char], start: usize, end: usize) -> Self {
        Self {
            kind,
            lexeme,
            start,
            end
        }
    }
}

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum TokenKind {
    Number,
    String,
    Char,
    Operator,
    Keyword,
    Flowword,
    Type,
    Ident,
    Comment,
    Whitespace,
    EOL,
    Unknown
}

impl Default for TokenKind {
    fn default() -> Self {
        Self::Unknown
    }
}

#[derive(Debug, Clone, Copy, )]
enum ParseStep {
    Continue,
    Break
}

#[derive(Debug, Clone)]
pub struct Tokenizer {
    syntax: Syntax,
    line: Vec<char>,
    i: usize,
    is_prev_sep: bool,
    quote: Option<char>,
    nested_comments: u32 // # of nested comments
}

impl Tokenizer {
    pub fn new(syntax: Syntax) -> Self {
        Self {
            syntax,
            line: vec![],
            i: 0,
            is_prev_sep: false,
            quote: None,
            nested_comments: 0
        }
    }

    /// Sets the line for the tokenizer to be the given one.
    pub fn apply_line(&mut self, line: &str) {
        self.line = line.chars().collect();
        self.i = 0;
        self.is_prev_sep = true;
    } 

    fn advance(&mut self) {
        self.i += 1;
    }

    fn advance_n(&mut self, n: usize) {
        self.i += n;
    }

    fn peek(&mut self) -> char {
        self.line[self.i+1]
    }

    fn peek_n(&mut self, n: usize) -> &[char] {
        &self.line[self.i+1..=self.i+n]
    }

    fn check(&mut self, str: &str) -> bool {
        str == &String::from_iter(self.peek_n(str.len()))
    }

    pub fn tokenize(&mut self) -> Vec<Token> {
        if let Language::Unknown = self.syntax.lang() {
            return vec![];
        }

        let mut tokens = Vec::with_capacity(5); // Assume 5 tokens is common enough to preallocate?

        let mut current_token = if let Some(_) = self.quote {
            Some(Token::new(TokenKind::String, &[], 0, 0))
        } else if self.nested_comments > 0 {
            Some(Token::new(TokenKind::Comment, &[], 0, 0))
        } else {
            None
        };
        
        loop {
            let ch = self.line[self.i];

            // Highlight Single-line Comment
            if let Some(ln_comment) = self.syntax.ln_comment() {
                if self.quote.is_none() &&
                    self.check(&ln_comment)
                {
                    current_token = None;

                    tokens.push(Token::new(TokenKind::Comment, &[], self.i, self.line.len() - 1));
                    break;
                }
            }

            // Highlight Multi-line Comment
            if let Some((mc_start, mc_end)) = self.syntax.multi_comment() {
                if self.quote.is_none() {
                    let start_len = mc_start.len();
                    let end_len = mc_end.len();

                    if self.check(&mc_start) {
                        current_token = Some(Token::new(TokenKind::Comment, &[], self.i, self.i + start_len));

                        self.nested_comments += 1;
                        self.advance_n(start_len);
                        continue;
                    }

                    if self.nested_comments > 0 {
                        current_token.unwrap().end += 1;

                        if self.check(&mc_end) {
                            current_token.unwrap().end += end_len;
                            tokens.push(current_token.unwrap());
                            current_token = None;
                            
                            if checkflags!(NESTED_COMMENTS in self.syntax.flags()) {
                                self.nested_comments -= 1;
                            } else {
                                self.nested_comments = 0;
                            }

                            self.is_prev_sep = true;
                            self.advance_n(end_len);
                            continue;
                        } else {
                            current_token.unwrap().end += 1;
                            self.advance();
                            continue;
                        }
                    }
                }
            }

            // Tokenize Keywords
            if self.is_prev_sep {
                if self.quote.is_none() {
                    for keyword in self.syntax.keywords() {
                        let len = keyword.len();

                        if self.check(&keyword) &&
                            (self.line.len() == self.i + len || 
                            is_sep(self.line[self.i + len]))
                        {
                            current_token = Some(Token::new(
                                TokenKind::Keyword, 
                                &self.line[self.i..self.i+len], 
                                self.i,
                                self.i + len));
                            tokens.push(current_token.unwrap());
                            current_token = None;

                            self.advance_n(len);

                            self.is_prev_sep = false;
                            break;
                        }
                    }
                }

                if !self.is_prev_sep {
                    if self.i < self.line.len() {
                        if is_sep(self.line[self.i]) {
                            self.is_prev_sep = true;
                        }
                    }
                    continue;
                }
            }

            // Highlight Flowwords
            if self.is_prev_sep {
                if self.quote.is_none() {
                    for flowword in self.syntax.flowwords() {
                        let len = flowword.len();

                        if self.check(&flowword) &&
                            (self.line.len() == self.i + len || 
                            is_sep(self.line[self.i + len]))
                        {
                            current_token = Some(Token::new(
                                TokenKind::Flowword, 
                                &self.line[self.i..self.i+len], 
                                self.i,
                                self.i + len));
                            tokens.push(current_token.unwrap());
                            current_token = None;

                            self.advance_n(len);

                            self.is_prev_sep = false;
                            break;
                        }
                    }
                }

                if !self.is_prev_sep {
                    if self.i < self.line.len() {
                        if is_sep(self.line[self.i]) {
                            self.is_prev_sep = true;
                        }
                    }
                    continue;
                }
            }

            // Tokenize Common Types
            if self.is_prev_sep {
                if self.quote.is_none() {
                    for common_type in self.syntax.common_types() {
                        let len = common_type.len();

                        if self.check(&common_type) &&
                            (self.line.len() == self.i + len || 
                            is_sep(self.line[self.i + len]))
                        {
                            current_token = Some(Token::new(
                                TokenKind::Type, 
                                &self.line[self.i..self.i+len], 
                                self.i,
                                self.i + len));
                            tokens.push(current_token.unwrap());
                            current_token = None;

                            self.advance_n(len);

                            self.is_prev_sep = false;
                            break;
                        }
                    }
                }

                if !self.is_prev_sep {
                    if self.i < self.line.len() {
                        if is_sep(self.line[self.i]) {
                            self.is_prev_sep = true;
                        }
                    }
                    continue;
                }
            }

            // Tokenize Strings
            if checkflags!(HIGHLIGHT_STRINGS in self.syntax.flags())
            {
                // Already in string
                if let Some(delim) = self.quote {
                    current_token.unwrap().end += 1;

                    // Escape character
                    if ch == '\\' && self.i + 1 < self.line.len() {
                        self.advance_n(2);
                        continue;
                    }

                    if ch == delim {
                        self.quote = None;
                        current_token.unwrap().lexeme = &self.line[current_token.unwrap().start..self.i];
                        tokens.push(current_token.unwrap());
                        current_token = None;
                    }

                    self.is_prev_sep = true;
                    self.advance();
                    continue;
                // Create new string
                } else if ch == '"' || ch == '\'' {
                    self.quote = Some(ch);
                    current_token = Some(Token::new(
                        TokenKind::String, 
                        &[], 
                        self.i, 
                        self.i+1
                    ));
                    self.advance();
                    continue;
                }
            }
                
            // Tokenize Number
            if checkflags!(HIGHLIGHT_NUMBERS in self.syntax.flags()) &&
                ch.is_digit(10)
            {
                if self.is_prev_sep {
                    current_token = Some(Token::new(
                        TokenKind::Number,
                        &self.line[self.i..self.i+1],
                        self.i,
                        self.i+1
                    ));

                    self.is_prev_sep = false;
                    self.advance();
                    continue;
                } else if let Some(Token { 
                    kind: TokenKind::Number, 
                    ref mut lexeme,
                    start,
                    ref mut end, 
                    .. 
                }) = current_token {
                    *lexeme = &self.line[start..*end+1];
                    *end += 1;

                    self.advance();
                    continue;
                }
            } 

            // Push number token
            if checkflags!(HIGHLIGHT_NUMBERS in self.syntax.flags()) {
                if let Some(Token {
                    kind: TokenKind::Number,
                    ..
                }) = current_token {
                    tokens.push(current_token.unwrap());
                    current_token = None;
                }
            }

            // Tokenize Identifiers 
            if !is_sep(ch) {
                if self.is_prev_sep {
                    current_token = Some(Token::new(
                        TokenKind::Ident, 
                        &[], 
                        self.i, 
                        self.i + 1
                    ));
                } else if let Some(Token {
                    kind: TokenKind::Ident,
                    ref mut lexeme,
                    start,
                    ref mut end
                }) = current_token {
                    *lexeme = &self.line[start..*end+1];
                    *end += 1;

                    self.advance();
                    continue;
                }
            }

            self.is_prev_sep = is_sep(ch);
            self.advance();
        }

        tokens
    }
}